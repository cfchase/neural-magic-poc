apiVersion: serving.kserve.io/v1alpha1
kind: ServingRuntime
labels:
  opendatahub.io/dashboard: "true"
metadata:
  annotations:
    openshift.io/display-name: DeepSparse Runtime
  name: deepsparse-runtime
spec:
  volumes:
    - name: kserve-aux
      emptyDir: {}
  containers:
    - args:
        - >
          cp -r /mnt/models/deployment/* /mnt/models-aux &&

          deepsparse.server --integration openai --config-file /server-config.yaml --port 8080
      command:
        - /bin/sh
        - -c
      image: quay.io/ltomasbo/neural-magic:deepsparse
      name: kserve-container
      ports:
        - containerPort: 8080
          protocol: TCP
      volumeMounts:
        - name: kserve-aux
          readOnly: false
          mountPath: /mnt/models-aux
  multiModel: false
  supportedModelFormats:
    - autoSelect: true
      name: onnx
